{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remote↔Central perfSONAR Mesh: Automated Setup & Archiving\n",
    "\n",
    "This notebook provisions a **central VM** and multiple **remote VMs**, installs perfSONAR components on each, wires up **pSConfig** for test orchestration, and configures **local and optional central archiving** so results appear in Grafana.\n",
    "\n",
    "## What this notebook does\n",
    "\n",
    "* **Provisioning**\n",
    "\n",
    "  * Creates one **central VM** and N **remote VMs**.\n",
    "  * Installs on **all VMs**: `perfsonar-testpoint`, `perfsonar-archive`, and `perfsonar-grafana`.\n",
    "* **Configuration**\n",
    "\n",
    "  * **Central** publishes a **pSConfig** template describing all hosts and archives.\n",
    "  * **Remote Nodes** subscribe to the central template and also load a **local pSConfig** (self + central).\n",
    "* **Measurements**\n",
    "\n",
    "  * Schedules the following tests **in both directions** (A→B and B→A where applicable):\n",
    "\n",
    "    * **Throughput:** `iperf3` (e.g., `-P 4 -t 60 -i 10 -O 10`)\n",
    "    * **Latency:** `owping`, `twping`, `halfping`\n",
    "    * **RTT:** `ping`, `tcpping`\n",
    "    * **MTU:** `fwmtu`\n",
    "    * **Clock:** `psclock`\n",
    "    * **Trace:** `traceroute`\n",
    "  * Test cadences are parameterized; defaults can be set at the top of the notebook.\n",
    "* **Archiving**\n",
    "\n",
    "  * **Local archive on each remote VM** via HTTP archiver → Logstash → OpenSearch.\n",
    "  * **Optional central archiving** (mirrored submission) for fleet-wide dashboards.\n",
    "* **Visualization**\n",
    "\n",
    "  * Each VM runs Grafana with perfSONAR dashboards (OpenSearch or pSConfig-driven views).\n",
    "\n",
    "## Key parameters (set at the top)\n",
    "\n",
    "* `TOTAL_NODE_CNT = 3`. Controls the number of nodes/VMs to use for the experiment `1(Central) + (N-1) (Remote)`.\n",
    "* `TEST_INTERVAL = 10M`. Controls the test interval with allowed values `10M`, `2H`, `4H` and `6H`.\n",
    "* **Archive behavior:**\n",
    "  * Always send to **local** archive on each remote server.\n",
    "  * Optionally **mirror** to central by enabling `USE_CENTRAL_ARCHIVE = True`\n",
    "\n",
    "![](./images/perfsonar-psconfig.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the FABlib Library\n",
    "\n",
    "FABlib is used to programmatically create and manage FABRIC resources such as slices and VMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ipaddress import ip_address, IPv4Address, IPv6Address, IPv4Network, IPv6Network\n",
    "import ipaddress, os, json\n",
    "\n",
    "from fabrictestbed_extensions.fablib.fablib import FablibManager as fablib_manager\n",
    "\n",
    "fablib = fablib_manager()\n",
    "                     \n",
    "fablib.show_config();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create the Experiment Slice\n",
    "\n",
    "This step provisions the VMs on the FABRIC testbed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "slice_name = 'perfSonar-fabric-multi-site'\n",
    "\n",
    "TOTAL_NODE_CNT = 2\n",
    "\n",
    "sites = fablib.get_random_sites(TOTAL_NODE_CNT)\n",
    "print(f\"Sites: {sites}\")\n",
    "\n",
    "central_node_name = \"central\"\n",
    "remote_node_name = \"remote\"\n",
    "\n",
    "USE_CENTRAL_ARCHIVE = False\n",
    "TEST_INTERVAL = '10M' # Allowed values 10M, 2H, 4H, 6H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create Slice\n",
    "slice = fablib.new_slice(name=slice_name)\n",
    "\n",
    "for i, s in enumerate(sites):\n",
    "    prefix = central_node_name if i == 0 else remote_node_name\n",
    "\n",
    "    net = slice.add_l3network(name=f\"{s}-l3\", type='IPv4')\n",
    "\n",
    "    node = slice.add_node(\n",
    "        name=f\"{prefix}-{s}\",\n",
    "        site=s,\n",
    "        image=\"default_ubuntu_24\",\n",
    "        cores=16,\n",
    "        ram=32,\n",
    "        disk=100\n",
    "    )\n",
    "\n",
    "    iface = node.add_component(model='NIC_Basic', name='nic1').get_interfaces()[0]\n",
    "    iface.set_mode('auto')\n",
    "    net.add_interface(iface)\n",
    "\n",
    "    node.add_route(subnet=fablib.FABNETV4_SUBNET, next_hop=net.get_gateway())\n",
    "\n",
    "\n",
    "\n",
    "#Submit Slice Request\n",
    "slice.submit();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure `/etc/hosts`\n",
    "\n",
    "For consistent name resolution across the fleet, update `/etc/hosts` on **every** VM with the same mappings.\n",
    "\n",
    "**Steps**\n",
    "\n",
    "* Add an entry for each node: IP address followed by its hostname (and optional aliases).\n",
    "* Keep the file identical on all nodes to prevent lookup mismatches during monitoring/orchestration.\n",
    "\n",
    "**Example**\n",
    "\n",
    "```\n",
    "10.128.1.2    central-STAR\n",
    "10.128.127.2  remote-RUTG\n",
    "10.128.254.2  remote-NEWY\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etc_hosts = \"\"\n",
    "for server in slice.get_nodes():\n",
    "    print(f\"node: {server.get_name()}\")\n",
    "    server_ip=server.get_interface(network_name=f\"{server.get_site()}-l3\").get_ip_addr()\n",
    "    etc_hosts += f\"{server_ip} {server.get_name()}\\n\"\n",
    "\n",
    "for server in slice.get_nodes():\n",
    "    server.execute(f'sudo sh -c \\'echo \"{etc_hosts}\" >> /etc/hosts\\'')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install perfSONAR stack (Testpoint, Archive, Grafana)\n",
    "\n",
    "Install the full perfSONAR stack on **every** VM—both central and remote—for a consistent setup:\n",
    "\n",
    "* **Testpoint**: pScheduler and measurement tools.\n",
    "* **Archive**: Logstash/OpenSearch pipeline for storing results.\n",
    "* **Grafana**: Dashboards for visualization.\n",
    "\n",
    "This ensures each node can run tests, store results locally, and (optionally) mirror data to the central archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_map = {}\n",
    "central_host = \"\"\n",
    "for n in slice.get_nodes():\n",
    "    n.upload_directory('node_tools','.')\n",
    "    ip_addr = n.get_interface(network_name=f\"{n.get_site()}-l3\").get_ip_addr() \n",
    "    ip_map[n.get_name()] = ip_addr\n",
    "    if central_node_name in n.get_name():\n",
    "        central_host = n.get_name()\n",
    "    n.execute('sudo node_tools/perfsonar-install.sh', quiet=True, output_file=f\"{n.get_name()}.log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archive access control — update Apache `/logstash` allowlist & auth\n",
    "\n",
    "Lock down the Logstash ingest endpoint so only approved hosts (and/or authenticated clients) can post results.\n",
    "\n",
    "**Steps**\n",
    "\n",
    "1. **Edit the `/logstash` location block**\n",
    "   File: `/etc/apache2/conf-available/apache-logstash.conf`\n",
    "\n",
    "```apache\n",
    "# ... existing ProxyPass/ProxyPassReverse for /logstash ...\n",
    "\n",
    "<Location \"/logstash\">\n",
    "  AuthType Basic\n",
    "  AuthName \"Logstash Ingest\"\n",
    "  # User file created by the archive install (adjust if different)\n",
    "  AuthUserFile /etc/perfsonar/opensearch/logstash_login\n",
    "\n",
    "  # Allow either a valid user OR specific IPs (including localhost)\n",
    "  <RequireAny>\n",
    "    Require valid-user\n",
    "    Require ip 127.0.0.1 ::1\n",
    "    # Add remote testpoints here (examples):\n",
    "    Require ip 10.128.127.0/24\n",
    "    Require ip 203.0.113.45\n",
    "  </RequireAny>\n",
    "</Location>\n",
    "```\n",
    "\n",
    "3. **Validate & reload Apache**\n",
    "\n",
    "```bash\n",
    "sudo apachectl -t\n",
    "sudo systemctl reload apache2\n",
    "```\n",
    "\n",
    "4. **Quick checks**\n",
    "\n",
    "* On the archive host: `sudo tail -f /var/log/apache2/access.log /var/log/apache2/error.log`\n",
    "* From a remote VM, run a test that uses the HTTP archiver, then on the archive:\n",
    "\n",
    "  ```bash\n",
    "  pscheduler archiving-summary PT30M\n",
    "  ```\n",
    "\n",
    "  You should see successes increase.\n",
    "\n",
    "**Notes**\n",
    "\n",
    "* Keep HTTPS enabled for `/logstash` and rotate credentials as needed.\n",
    "* Using both `Require valid-user` and `Require ip` lets you mix “trusted by IP” remote VMs with authenticated clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ips = ip_map.values()\n",
    "for n in slice.get_nodes():\n",
    "    n.execute(f'sudo node_tools/allow_logstash_ips.sh  {\" \".join(map(str, all_ips))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hosts = [x for name, ip in ip_map.items() for x in (name, str(ip))]\n",
    "print(all_hosts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pSConfig\n",
    "\n",
    "Orchestrate tests with a central template and have remote VMs subscribe to it.\n",
    "\n",
    "### Central VM: build & publish the mesh template\n",
    "\n",
    "1. Create a JSON template defining **addresses, groups, tests, schedules, and archives** (the HTTP `/logstash` archive) using `psconfig/psconfig_builder.py`.\n",
    "2. Publish it so remote VMs can subscribe:\n",
    "\n",
    "   ```bash\n",
    "   sudo psconfig publish psconfig/psconfig.json\n",
    "   sudo psconfig remote add https://localhost/psconfig/psconfig.json\n",
    "   ```\n",
    "\n",
    "### Remote VMs: subscribe (and auto-configure archives)\n",
    "\n",
    "1. Create a JSON template defining **addresses, groups, tests, schedules, and archives** (the HTTP `/logstash` archive) using `psconfig/psconfig_builder.py`.\n",
    "2. Add a small **local** template on each remote VM (self + central) for specific extras, and subscribe to it as a file:\n",
    "\n",
    "   ```bash\n",
    "   sudo psconfig publish psconfig/psconfig.json\n",
    "   sudo psconfig remote add https://localhost/psconfig/psconfig.json\n",
    "   ```\n",
    "\n",
    "### Verify\n",
    "\n",
    "* After \\~1 minute, tasks should appear:\n",
    "\n",
    "  ```bash\n",
    "  pscheduler schedule\n",
    "  pscheduler archiving-summary PT30M\n",
    "  ```\n",
    "* In Grafana (central and/or remote), confirm data is arriving for the time window covering the first runs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in slice.get_nodes():\n",
    "    n.upload_directory('psconfig', '.')\n",
    "\n",
    "    if central_host in n.get_name():\n",
    "        n.execute(f'python3 psconfig/psconfig_builder.py --base_config_file psconfig/base_psconfig.json '\n",
    "                  f'--output_file psconfig/psconfig.json --no_add_tests --host_list {\" \".join(map(str, all_hosts))}')\n",
    "    else:\n",
    "        if USE_CENTRAL_ARCHIVE:\n",
    "            cmd = (\n",
    "                    f\"python3 psconfig/psconfig_builder.py \"\n",
    "                    f\"--base_config_file psconfig/base_psconfig.json \"\n",
    "                    f\"--output_file psconfig/psconfig.json \"\n",
    "                    f\"--remote {ip_map[central_host]} \"\n",
    "                    f'--host_list {n.get_name()} {ip_map[n.get_name()]} {central_host} {ip_map[central_host]}'\n",
    "                )\n",
    "        else:\n",
    "            cmd = (\n",
    "                    f\"python3 psconfig/psconfig_builder.py \"\n",
    "                    f\"--base_config_file psconfig/base_psconfig.json \"\n",
    "                    f\"--output_file psconfig/psconfig.json \"\n",
    "                    f'--host_list {n.get_name()} {ip_map[n.get_name()]} {central_host} {ip_map[central_host]}'\n",
    "                )\n",
    "            \n",
    "        print(cmd)\n",
    "        n.execute(cmd)\n",
    "\n",
    "    n.execute('sudo psconfig validate psconfig/psconfig.json')\n",
    "    n.execute('sudo psconfig publish psconfig/psconfig.json')\n",
    "\n",
    "    n.execute('sudo psconfig remote add \"https://localhost/psconfig/psconfig.json\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SSH Tunnel (Grafana Access)\n",
    "\n",
    "Use an SSH local port forward so you can open the remote Grafana UI in your local browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fablib.create_ssh_tunnel_config(overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## perfSONAR Toolkit Grafana\n",
    "\n",
    "Use SSH local port forwards to map your **local** ports to each remote host’s **HTTPS (443)**. Then open the URLs below in your browser.\n",
    "\n",
    "### Central Node (maps local 8443 → remote 443)\n",
    "\n",
    "```bash\n",
    "ssh -N -L 8443:localhost:443 <USER>@<CENTRAL_IP>\n",
    "# Browse: https://127.0.0.1:8443\n",
    "```\n",
    "\n",
    "### Remote VMs (add one tunnel per VM)\n",
    "\n",
    "```bash\n",
    "# Remote-1  (local 8444 → remote-1:443)\n",
    "ssh -N -L 8444:localhost:443 <USER>@<REMOTE1_IP>\n",
    "# Browse: https://127.0.0.1:8444\n",
    "\n",
    "# Remote-2  (local 8445 → remote-2:443)\n",
    "ssh -N -L 8445:localhost:443 <USER>@<REMOTE2_IP>\n",
    "# Browse: https://127.0.0.1:8445\n",
    "```\n",
    "\n",
    "> Tip: add `-f` to send the tunnel to the background (`ssh -fN -L ...`).\n",
    "> If remote VMs are only reachable via central, use a jump host:\n",
    "> `ssh -J <USER>@<CENTRAL_IP> -N -L 8444:localhost:443 <USER>@REMOTE1_IP>`\n",
    "\n",
    "### Notes\n",
    "\n",
    "* perfSONAR/Grafana often uses a self-signed cert — your browser may warn; proceed if you trust the host.\n",
    "* Log in with your Grafana credentials.\n",
    "* Stop a tunnel with `Ctrl+C` (or kill the background `ssh` if you used `-f`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Port on your local machine that you want to map the File Browser to.\n",
    "local_port=8443\n",
    "# Local interface to map the File Browser to (can be `localhost`)\n",
    "local_host='127.0.0.1'\n",
    "\n",
    "# Port on the node used by the File Browser Service\n",
    "target_port='443'\n",
    "\n",
    "for n in slice.get_nodes():\n",
    "    # Username/node on FABRIC\n",
    "    target_host=f'{n.get_username()}@{n.get_management_ip()}'\n",
    "    print(f'Tunnel command for {n.get_name()}')\n",
    "    print(f'ssh  -L {local_host}:{local_port}:127.0.0.1:{target_port} -i {os.path.basename(fablib.get_default_slice_public_key_file())[:-4]} -F ssh_config {target_host}')\n",
    "    local_port += 1\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification\n",
    "\n",
    "### pScheduler health\n",
    "\n",
    "```bash\n",
    "# Basic end-to-end checks (network, tools, auth, archives)\n",
    "pscheduler troubleshoot\n",
    "\n",
    "# What’s scheduled / running\n",
    "pscheduler schedule\n",
    "pscheduler task --state on-run\n",
    "\n",
    "# Archiving success/fail in the last 30 minutes\n",
    "pscheduler archiving-summary PT30M\n",
    "```\n",
    "\n",
    "### OpenSearch spot-checks (recent docs)\n",
    "\n",
    "```bash\n",
    "# Replace with your archive host and credentials\n",
    "curl -k -u '<user>:<pass>' \\\n",
    "  'https://<archive-host>/opensearch/pscheduler*/_search?size=5' \\\n",
    "  -H 'Content-Type: application/json' -d '{\n",
    "    \"sort\": [{\"pscheduler.start_time\":{\"order\":\"desc\"}}]\n",
    "  }' | jq '.[].hits.hits[]._source\n",
    "           | { time: .pscheduler.start_time,\n",
    "               type: .test.type,\n",
    "               src: .test.spec.source,\n",
    "               dst: .test.spec.dest,\n",
    "               summary: .summary }'\n",
    "```\n",
    "\n",
    "You should see `src` and `dst` populated; if blank, ensure tests specify **both** `--source` and `--dest` (pSConfig does this automatically).\n",
    "\n",
    "### Grafana dashboards\n",
    "\n",
    "* Open the dashboard and set the time range to include your latest runs.\n",
    "* Confirm panels populate and show **source/dest** labels.\n",
    "* If no data:\n",
    "\n",
    "  * Check the Grafana data source (OpenSearch URL, index `pscheduler*`, time field `pscheduler.start_time`).\n",
    "  * Re-check `pscheduler archiving-summary` and the archive’s Apache/Logstash logs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete the Slice\n",
    "\n",
    "Please delete your slice when you are done with your experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "slice = fablib.get_slice(slice_name)\n",
    "slice.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
